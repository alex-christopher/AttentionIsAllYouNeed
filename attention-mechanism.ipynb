{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca3d49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input is :  torch.Size([4, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "batch_size = 4\n",
    "sequence_length = 64\n",
    "embed_dim = 128\n",
    "\n",
    "x = torch.randn(batch_size, sequence_length, embed_dim)\n",
    "print(\"Shape of input is : \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a9095f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26b5276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447a1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = (x @ x.transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c19cd2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5227622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(394.5553)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d56de33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1178e+01,  5.7155e-01,  1.4334e+00,  ..., -2.2718e+00,\n",
       "           1.1709e+00, -1.4546e+00],\n",
       "         [ 5.7155e-01,  1.1902e+01,  1.7159e+00,  ...,  2.0412e-02,\n",
       "           1.1101e+00, -8.6087e-01],\n",
       "         [ 1.4334e+00,  1.7159e+00,  1.0122e+01,  ..., -6.0288e-01,\n",
       "           9.0337e-01, -4.3254e-01],\n",
       "         ...,\n",
       "         [-2.2718e+00,  2.0412e-02, -6.0288e-01,  ...,  1.2256e+01,\n",
       "          -5.6293e-01,  1.1852e+00],\n",
       "         [ 1.1709e+00,  1.1101e+00,  9.0337e-01,  ..., -5.6293e-01,\n",
       "           9.9783e+00, -1.3724e+00],\n",
       "         [-1.4546e+00, -8.6087e-01, -4.3254e-01,  ...,  1.1852e+00,\n",
       "          -1.3724e+00,  1.1909e+01]],\n",
       "\n",
       "        [[ 9.8203e+00, -1.0809e+00,  1.7134e+00,  ..., -1.8418e+00,\n",
       "          -7.9413e-01, -2.6518e-01],\n",
       "         [-1.0809e+00,  1.4634e+01, -1.1969e+00,  ...,  1.6224e+00,\n",
       "          -7.3279e-01,  6.2115e-01],\n",
       "         [ 1.7134e+00, -1.1969e+00,  1.0856e+01,  ...,  1.5530e+00,\n",
       "           7.0712e-01,  1.8886e+00],\n",
       "         ...,\n",
       "         [-1.8418e+00,  1.6224e+00,  1.5530e+00,  ...,  1.1163e+01,\n",
       "           8.1899e-01,  1.9053e+00],\n",
       "         [-7.9413e-01, -7.3279e-01,  7.0712e-01,  ...,  8.1899e-01,\n",
       "           1.2525e+01,  1.6398e+00],\n",
       "         [-2.6518e-01,  6.2115e-01,  1.8886e+00,  ...,  1.9053e+00,\n",
       "           1.6398e+00,  1.1743e+01]],\n",
       "\n",
       "        [[ 1.0764e+01, -2.9246e-01, -4.1651e-01,  ..., -6.7007e-01,\n",
       "          -5.7375e-01,  1.9978e-02],\n",
       "         [-2.9246e-01,  1.0930e+01,  1.3973e+00,  ..., -9.4546e-01,\n",
       "          -1.6571e+00, -2.0780e+00],\n",
       "         [-4.1651e-01,  1.3973e+00,  1.0839e+01,  ..., -3.3248e-01,\n",
       "           3.6434e-01,  2.0426e+00],\n",
       "         ...,\n",
       "         [-6.7007e-01, -9.4546e-01, -3.3248e-01,  ...,  9.5654e+00,\n",
       "          -6.4719e-01, -2.0387e-03],\n",
       "         [-5.7375e-01, -1.6571e+00,  3.6434e-01,  ..., -6.4719e-01,\n",
       "           9.1604e+00, -7.3649e-01],\n",
       "         [ 1.9978e-02, -2.0780e+00,  2.0426e+00,  ..., -2.0387e-03,\n",
       "          -7.3649e-01,  1.3753e+01]],\n",
       "\n",
       "        [[ 1.2017e+01, -5.2870e-01,  1.1614e-01,  ..., -9.8646e-02,\n",
       "          -8.0773e-01,  2.7205e-01],\n",
       "         [-5.2870e-01,  9.4843e+00, -6.4811e-01,  ..., -2.2903e+00,\n",
       "          -2.5668e-01, -4.3098e-01],\n",
       "         [ 1.1614e-01, -6.4811e-01,  9.1583e+00,  ...,  6.0604e-01,\n",
       "           9.9302e-01, -1.1710e+00],\n",
       "         ...,\n",
       "         [-9.8646e-02, -2.2903e+00,  6.0604e-01,  ...,  1.3043e+01,\n",
       "          -6.3765e-01, -6.8305e-01],\n",
       "         [-8.0773e-01, -2.5668e-01,  9.9302e-01,  ..., -6.3765e-01,\n",
       "           1.0049e+01,  3.3550e-01],\n",
       "         [ 2.7205e-01, -4.3098e-01, -1.1710e+00,  ..., -6.8305e-01,\n",
       "           3.3550e-01,  1.0151e+01]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = (x @ x.transpose(1, 2)) / (embed_dim ** 0.5)\n",
    "\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b781a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.9830e-01, 2.4720e-05, 5.8524e-05,  ..., 1.4395e-06,\n",
       "          4.5013e-05, 3.2593e-06],\n",
       "         [1.1991e-05, 9.9931e-01, 3.7659e-05,  ..., 6.9105e-06,\n",
       "          2.0548e-05, 2.8627e-06],\n",
       "         [1.6773e-04, 2.2250e-04, 9.9512e-01,  ..., 2.1892e-05,\n",
       "          9.8727e-05, 2.5957e-05],\n",
       "         ...,\n",
       "         [4.9053e-07, 4.8544e-06, 2.6028e-06,  ..., 9.9959e-01,\n",
       "          2.7089e-06, 1.5559e-05],\n",
       "         [1.4898e-04, 1.4020e-04, 1.1402e-04,  ..., 2.6312e-05,\n",
       "          9.9579e-01, 1.1712e-05],\n",
       "         [1.5702e-06, 2.8430e-06, 4.3632e-06,  ..., 2.1998e-05,\n",
       "          1.7047e-06, 9.9935e-01]],\n",
       "\n",
       "        [[9.9475e-01, 1.8340e-05, 2.9990e-04,  ..., 8.5696e-06,\n",
       "          2.4431e-05, 4.1463e-05],\n",
       "         [1.4962e-07, 9.9996e-01, 1.3323e-07,  ..., 2.2336e-06,\n",
       "          2.1192e-07, 8.2069e-07],\n",
       "         [1.0685e-04, 5.8183e-06, 9.9815e-01,  ..., 9.1012e-05,\n",
       "          3.9059e-05, 1.2731e-04],\n",
       "         ...,\n",
       "         [2.2458e-06, 7.1751e-05, 6.6945e-05,  ..., 9.9838e-01,\n",
       "          3.2131e-05, 9.5210e-05],\n",
       "         [1.6419e-06, 1.7458e-06, 7.3678e-06,  ..., 8.2399e-06,\n",
       "          9.9965e-01, 1.8723e-05],\n",
       "         [6.0892e-06, 1.4774e-05, 5.2475e-05,  ..., 5.3354e-05,\n",
       "          4.0915e-05, 9.9922e-01]],\n",
       "\n",
       "        [[9.9769e-01, 1.5750e-05, 1.3912e-05,  ..., 1.0797e-05,\n",
       "          1.1888e-05, 2.1526e-05],\n",
       "         [1.3346e-05, 9.9849e-01, 7.2312e-05,  ..., 6.9466e-06,\n",
       "          3.4097e-06, 2.2383e-06],\n",
       "         [1.2907e-05, 7.9167e-05, 9.9735e-01,  ..., 1.4038e-05,\n",
       "          2.8180e-05, 1.5093e-04],\n",
       "         ...,\n",
       "         [3.5619e-05, 2.7045e-05, 4.9922e-05,  ..., 9.9287e-01,\n",
       "          3.6443e-05, 6.9471e-05],\n",
       "         [5.8760e-05, 1.9888e-05, 1.5014e-04,  ..., 5.4600e-05,\n",
       "          9.9214e-01, 4.9935e-05],\n",
       "         [1.0862e-06, 1.3329e-07, 8.2096e-06,  ..., 1.0626e-06,\n",
       "          5.0979e-07, 9.9991e-01]],\n",
       "\n",
       "        [[9.9936e-01, 3.5594e-06, 6.7830e-06,  ..., 5.4720e-06,\n",
       "          2.6927e-06, 7.9275e-06],\n",
       "         [4.4605e-05, 9.9534e-01, 3.9585e-05,  ..., 7.6622e-06,\n",
       "          5.8549e-05, 4.9184e-05],\n",
       "         [1.1725e-04, 5.4603e-05, 9.9106e-01,  ..., 1.9138e-04,\n",
       "          2.8181e-04, 3.2369e-05],\n",
       "         ...,\n",
       "         [1.9614e-06, 2.1916e-07, 3.9684e-06,  ..., 9.9982e-01,\n",
       "          1.1441e-06, 1.0934e-06],\n",
       "         [1.9202e-05, 3.3317e-05, 1.1625e-04,  ..., 2.2762e-05,\n",
       "          9.9630e-01, 6.0235e-05],\n",
       "         [5.0975e-05, 2.5237e-05, 1.2041e-05,  ..., 1.9614e-05,\n",
       "          5.4314e-05, 9.9516e-01]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mat = similarity.softmax(dim = 2)\n",
    "\n",
    "attn_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02a0a33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 64, 64]), torch.Size([4, 64, 128]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mat.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f75062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = (attn_mat @ x)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa972806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 20])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(10, 20)\n",
    "\n",
    "rand = torch.randn(4, 6, 10)\n",
    "\n",
    "linear(rand).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314fb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single head attention\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, embedding_dimension):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embedding_dimension\n",
    "\n",
    "        self.query = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.key = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.value = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        similarity = (q @ k.transpose(1, 2)) / self.embed_dim ** 0.5\n",
    "        attention = similarity.softmax(axis=2)\n",
    "        output = attention @ v\n",
    "\n",
    "rand = torch.randn(4, 64, 128)\n",
    "\n",
    "attn = Attention(embedding_dimension=128)\n",
    "attn(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b135953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dimension, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embedding_dimension\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "\n",
    "        self.multihead_qkv = nn.ModuleList()\n",
    "\n",
    "        for head in range(num_heads):\n",
    "            qkv_proj = nn.ModuleDict(\n",
    "                [\n",
    "                  [\"Q\", nn.Linear(self.embed_dim, self.head_dim)],\n",
    "                  [\"K\", nn.Linear(self.embed_dim, self.head_dim)],\n",
    "                  [\"V\", nn.Linear(self.embed_dim, self.head_dim)]  \n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.multihead_qkv.append(qkv_proj)\n",
    "\n",
    "        self.proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        head_outs = []\n",
    "\n",
    "        for head in self.multihead_qkv:\n",
    "\n",
    "            q = head[\"Q\"](x)\n",
    "            k = head[\"K\"](x)\n",
    "            v = head[\"V\"](x)\n",
    "\n",
    "            similarity = (q @ k.transpose(1, 2)) / self.head_dim ** 0.5\n",
    "            attention = similarity.softmax(axis=-1)\n",
    "            output = attention @ v\n",
    "\n",
    "            head_outs.append(output)\n",
    "\n",
    "        head_outs = torch.cat(head_outs, dim=-1)\n",
    "\n",
    "        out = self.proj(head_outs)\n",
    "\n",
    "        return out\n",
    "            \n",
    "\n",
    "rand = torch.randn(4, 64, 128)\n",
    "attn = MultiHeadAttention(128, 4)\n",
    "attn(rand).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d2f67e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inpur shape :  torch.Size([5, 10]) Output shape :  torch.Size([5, 30])\n",
      "Inpur shape :  torch.Size([5, 1, 2, 4, 10]) Output shape :  torch.Size([5, 1, 2, 4, 30])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(10, 30)\n",
    "\n",
    "tensor_1 = torch.randn(5, 10)\n",
    "tensor_1_out = fc(tensor_1)\n",
    "\n",
    "print(\"Inpur shape : \", tensor_1.shape, \"Output shape : \", tensor_1_out.shape)\n",
    "\n",
    "tensor_2 = torch.randn(5, 1, 2, 4, 10)\n",
    "tensor_2_out = fc(tensor_2)\n",
    "\n",
    "print(\"Inpur shape : \", tensor_2.shape, \"Output shape : \", tensor_2_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f9d07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(1, 8, 9)\n",
    "fc = nn.Linear(9, 9)\n",
    "\n",
    "q = fc(tensor)\n",
    "\n",
    "chunk1, chun2, chunk3 = torch.chunk(q, 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b947a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.2597, 0.7285, 0.6481],\n",
       "          [1.2363, 0.8279, 0.6588],\n",
       "          [0.8187, 0.6148, 0.5989],\n",
       "          [0.8854, 0.4790, 0.4740],\n",
       "          [1.2740, 1.0117, 0.7970],\n",
       "          [1.1715, 0.8315, 0.7771]],\n",
       "\n",
       "         [[1.5752, 1.3709, 0.8179],\n",
       "          [1.2145, 0.9876, 0.6341],\n",
       "          [1.9579, 1.7720, 0.8514],\n",
       "          [1.6245, 1.6110, 1.0023],\n",
       "          [1.5703, 1.2739, 0.5433],\n",
       "          [0.9940, 1.1083, 0.7120]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1, 2, 6, 4)\n",
    "b = torch.rand(1, 2, 4, 3)\n",
    "\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "155ed6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 128])\n",
      "torch.Size([4, 16, 128])\n"
     ]
    }
   ],
   "source": [
    "class SelfAttentionEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, attn_p = 0.0, proj_p = 0.0, bias = True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.query = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length, embed_dim = x.shape\n",
    "\n",
    "        print(x.shape)\n",
    "\n",
    "        q = self.query(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.key(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.value(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        attn = q @ k.transpose(-2, -1) * self.head_dim ** 0.5\n",
    "        attn = attn.softmax(axis=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = attn @ v\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(batch_size, sequence_length, embed_dim)\n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "\n",
    "rand = torch.randn(4, 16, 128)\n",
    "attn = SelfAttentionEncoder(128, 4)\n",
    "attn(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e0f4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n",
      "torch.Size([1, 6, 6]) torch.Size([1, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 6, 6]), torch.Size([1, 6, 6]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_attn = torch.rand(1, 6, 6)\n",
    "\n",
    "attention_mask = torch.tensor([1, 1, 1, 1, 0, 0]).unsqueeze(0).bool()\n",
    "print(attention_mask.shape)\n",
    "attention_mask = attention_mask.unsqueeze(1).repeat(1, 6, 1)\n",
    "print(attention_mask.shape, rand_attn.shape)\n",
    "\n",
    "# torch.softmax(rand_attn.masked_fill(~attention_mask, -float(\"inf\")), axis=-1)\n",
    "\n",
    "attention_mask.shape, rand_attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False]],\n",
      "\n",
      "         [[ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False]]]])\n"
     ]
    }
   ],
   "source": [
    "rand_attn = torch.rand(1, 2, 6, 6)\n",
    "\n",
    "attention_mask = torch.tensor([1, 1, 1, 1, 0, 0]).unsqueeze(0).bool()\n",
    "attention_mask = attention_mask.unsqueeze(1).unsqueeze(1)\n",
    "attention_mask = attention_mask.repeat(1, 2, 6, 1)\n",
    "print(attention_mask)\n",
    "\n",
    "# rand_attn.masked_fill_(~attention_mask, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3aa60987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention mask : \n",
      "tensor([[ True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False]])\n",
      "torch.Size([3, 5, 9])\n",
      "Attention mask\n",
      "tensor([[[ True,  True,  True, False, False]]])\n",
      "tensor([[[ 0.6316,  1.0843,  1.2473,  0.8408,  0.1527],\n",
      "         [-1.8561, -1.3194,  0.8943,  2.3284,  1.4364],\n",
      "         [-0.2901, -0.4388, -0.5369, -0.3559, -0.0659],\n",
      "         [-0.8728, -0.5808, -0.7983, -0.2802,  0.0417],\n",
      "         [ 1.0928,  0.4620, -1.7278, -2.6655, -1.3850]],\n",
      "\n",
      "        [[-0.4862,  2.3263,  0.9369, -0.4796, -1.5877],\n",
      "         [ 0.3433, -2.0136,  1.7547,  1.0691,  0.0433],\n",
      "         [ 0.4617, -1.6016, -1.8754, -0.0097,  1.6980],\n",
      "         [ 1.8979, -2.5033, -1.4901, -0.0056,  1.4520],\n",
      "         [-0.2775, -0.2503, -0.3614,  0.0843,  0.4318]],\n",
      "\n",
      "        [[ 0.8664,  1.0094,  0.8077, -0.3590, -0.6604],\n",
      "         [ 1.0388,  2.4786, -0.1004,  2.4877,  0.2935],\n",
      "         [ 0.1927,  1.3093, -0.6028,  1.4122,  0.5153],\n",
      "         [-0.8883, -0.5865, -0.9135, -0.8284,  0.4701],\n",
      "         [-1.4021, -1.3580, -1.4029,  0.1750,  1.0289]]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[[[ 0.6316,  1.0843,  1.2473,    -inf,    -inf],\n",
      "          [-1.8561, -1.3194,  0.8943,    -inf,    -inf],\n",
      "          [-0.2901, -0.4388, -0.5369,    -inf,    -inf],\n",
      "          [-0.8728, -0.5808, -0.7983,    -inf,    -inf],\n",
      "          [ 1.0928,  0.4620, -1.7278,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4862,  2.3263,  0.9369,    -inf,    -inf],\n",
      "          [ 0.3433, -2.0136,  1.7547,    -inf,    -inf],\n",
      "          [ 0.4617, -1.6016, -1.8754,    -inf,    -inf],\n",
      "          [ 1.8979, -2.5033, -1.4901,    -inf,    -inf],\n",
      "          [-0.2775, -0.2503, -0.3614,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.8664,  1.0094,  0.8077,    -inf,    -inf],\n",
      "          [ 1.0388,  2.4786, -0.1004,    -inf,    -inf],\n",
      "          [ 0.1927,  1.3093, -0.6028,    -inf,    -inf],\n",
      "          [-0.8883, -0.5865, -0.9135,    -inf,    -inf],\n",
      "          [-1.4021, -1.3580, -1.4029,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.2086,  0.2769,  0.2460, -0.0134, -0.1891],\n",
      "          [ 1.4910, -1.8474, -3.1431,  0.9862,  0.0162],\n",
      "          [ 0.9051, -1.1333, -2.0440,  0.7020, -0.1000],\n",
      "          [ 0.3263,  0.1389, -0.3202, -0.3898, -0.1384],\n",
      "          [-0.4223,  0.6561,  0.4415, -0.0482, -0.5150]],\n",
      "\n",
      "         [[-0.0888,  0.2234,  0.0174, -0.1555, -0.1155],\n",
      "          [-0.3042,  3.0537, -0.7944,  0.4687, -2.0636],\n",
      "          [-0.4194, -0.6974,  0.4569,  2.5973, -0.5751],\n",
      "          [ 0.3300, -2.0444,  0.3800,  0.1688,  1.2753],\n",
      "          [-0.1892, -0.2467,  0.2290,  0.4946, -0.0836]],\n",
      "\n",
      "         [[-0.0352,  0.2784,  0.1950,  0.7077, -0.1610],\n",
      "          [-0.2462, -0.1910, -0.2595, -0.3573,  0.0066],\n",
      "          [-0.0080, -0.4791, -0.2256, -0.5322,  0.0610],\n",
      "          [ 0.5261, -1.1342, -0.0818, -0.6024,  0.0878],\n",
      "          [ 0.1172, -0.4958, -0.0434, -0.0032, -0.0649]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1072, -0.5552, -0.7686,  0.6287,    -inf],\n",
      "          [ 0.0151, -0.3587, -0.8149,  0.7250,    -inf],\n",
      "          [ 0.0158, -0.2838, -0.7993,  0.6872,    -inf],\n",
      "          [-0.1513,  0.4995,  0.4266, -0.2871,    -inf],\n",
      "          [ 0.0887, -0.6524, -0.6318,  0.5809,    -inf]],\n",
      "\n",
      "         [[-0.0703,  0.1500,  0.3804,  0.7732,    -inf],\n",
      "          [ 0.4521,  0.1925,  0.1414,  0.1220,    -inf],\n",
      "          [ 0.6900,  0.2258,  0.3495,  0.2474,    -inf],\n",
      "          [ 0.6194, -0.3742, -0.3766, -1.5613,    -inf],\n",
      "          [-0.9566, -0.0819,  0.1139,  0.7776,    -inf]],\n",
      "\n",
      "         [[ 0.3205, -0.2789, -0.6257,  0.1251,    -inf],\n",
      "          [-0.1818, -0.2748, -0.4358, -0.0231,    -inf],\n",
      "          [ 0.2481, -0.3908, -0.7221, -0.3155,    -inf],\n",
      "          [ 0.1454,  0.5383,  0.8454,  0.4317,    -inf],\n",
      "          [-0.4047, -0.2211, -0.4045,  0.6858,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[[[0.2261, 0.3555, 0.4184, 0.0000, 0.0000],\n",
      "          [0.0545, 0.0932, 0.8524, 0.0000, 0.0000],\n",
      "          [0.3783, 0.3260, 0.2956, 0.0000, 0.0000],\n",
      "          [0.2927, 0.3920, 0.3153, 0.0000, 0.0000],\n",
      "          [0.6283, 0.3343, 0.0374, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0459, 0.7638, 0.1904, 0.0000, 0.0000],\n",
      "          [0.1924, 0.0182, 0.7893, 0.0000, 0.0000],\n",
      "          [0.8172, 0.1038, 0.0790, 0.0000, 0.0000],\n",
      "          [0.9560, 0.0117, 0.0323, 0.0000, 0.0000],\n",
      "          [0.3393, 0.3487, 0.3120, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3229, 0.3726, 0.3045, 0.0000, 0.0000],\n",
      "          [0.1805, 0.7617, 0.0578, 0.0000, 0.0000],\n",
      "          [0.2219, 0.6779, 0.1002, 0.0000, 0.0000],\n",
      "          [0.3005, 0.4064, 0.2930, 0.0000, 0.0000],\n",
      "          [0.3285, 0.3433, 0.3282, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1554, 0.2525, 0.2448, 0.1889, 0.1584],\n",
      "          [0.5326, 0.0189, 0.0052, 0.3215, 0.1219],\n",
      "          [0.4229, 0.0551, 0.0222, 0.3451, 0.1548],\n",
      "          [0.2882, 0.2389, 0.1510, 0.1408, 0.1811],\n",
      "          [0.1152, 0.3388, 0.2734, 0.1675, 0.1050]],\n",
      "\n",
      "         [[0.1856, 0.2536, 0.2064, 0.1736, 0.1807],\n",
      "          [0.0306, 0.8791, 0.0187, 0.0663, 0.0053],\n",
      "          [0.0393, 0.0298, 0.0944, 0.8029, 0.0336],\n",
      "          [0.1796, 0.0167, 0.1888, 0.1528, 0.4621],\n",
      "          [0.1525, 0.1440, 0.2317, 0.3022, 0.1695]],\n",
      "\n",
      "         [[0.1513, 0.2070, 0.1904, 0.3180, 0.1334],\n",
      "          [0.1914, 0.2022, 0.1888, 0.1712, 0.2464],\n",
      "          [0.2444, 0.1526, 0.1966, 0.1447, 0.2618],\n",
      "          [0.3699, 0.0703, 0.2014, 0.1197, 0.2387],\n",
      "          [0.2431, 0.1317, 0.2070, 0.2155, 0.2026]]],\n",
      "\n",
      "\n",
      "        [[[0.2765, 0.1426, 0.1152, 0.4658, 0.0000],\n",
      "          [0.2405, 0.1655, 0.1049, 0.4891, 0.0000],\n",
      "          [0.2415, 0.1790, 0.1069, 0.4726, 0.0000],\n",
      "          [0.1795, 0.3440, 0.3198, 0.1567, 0.0000],\n",
      "          [0.2778, 0.1324, 0.1352, 0.4545, 0.0000]],\n",
      "\n",
      "         [[0.1629, 0.2030, 0.2556, 0.3786, 0.0000],\n",
      "          [0.3103, 0.2393, 0.2274, 0.2230, 0.0000],\n",
      "          [0.3353, 0.2108, 0.2385, 0.2154, 0.0000],\n",
      "          [0.5398, 0.1999, 0.1994, 0.0610, 0.0000],\n",
      "          [0.0835, 0.2002, 0.2435, 0.4729, 0.0000]],\n",
      "\n",
      "         [[0.3623, 0.1990, 0.1407, 0.2980, 0.0000],\n",
      "          [0.2591, 0.2361, 0.2010, 0.3037, 0.0000],\n",
      "          [0.4039, 0.2132, 0.1531, 0.2299, 0.0000],\n",
      "          [0.1716, 0.2542, 0.3456, 0.2285, 0.0000],\n",
      "          [0.1619, 0.1945, 0.1619, 0.4817, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 3, 5, 5])\n",
      "torch.Size([3, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, attn_p = 0.0, proj_p = 0.0, bias = True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.query = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "\n",
    "    def forward(self, x, attention_mask = None):\n",
    "        batch_size, sequence_length, embed_dim = x.shape\n",
    "\n",
    "        print(x.shape)\n",
    "\n",
    "        q = self.query(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.key(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.value(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        attn = q @ k.transpose(-2, -1) * self.head_dim ** 0.5\n",
    "        \n",
    "        #############################################\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            print(\"Attention mask\")\n",
    "\n",
    "            attention_mask = attention_mask.unsqueeze(1).unsqueeze(1) # .repeat(1, 1, sequence_length, 1) Optional\n",
    "            print(attention_mask[0])\n",
    "            print(attn[0])\n",
    "\n",
    "            attn = attn.masked_fill_(~attention_mask, float(\"-inf\"))\n",
    "            print(attn)\n",
    "\n",
    "        #############################################\n",
    "\n",
    "        attn = attn.softmax(axis=-1)\n",
    "        print(attn)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = attn @ v\n",
    "        print(attn.shape)\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(batch_size, sequence_length, embed_dim)\n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "\n",
    "seq_lens = [3, 5, 4]\n",
    "embed_dim = 9\n",
    "num_heads = 3\n",
    "\n",
    "a = SelfAttention(embed_dim, num_heads)\n",
    "\n",
    "rand = torch.randn(len(seq_lens), max(seq_lens), embed_dim)\n",
    "\n",
    "masks = torch.nn.utils.rnn.pad_sequence([torch.ones(l) for l in seq_lens], batch_first=True, padding_value=0).bool()\n",
    "print(\"Attention mask : \")\n",
    "print(masks)\n",
    "\n",
    "output = a(rand, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False, False, False, False],\n",
       "        [ True,  True, False, False, False, False, False, False],\n",
       "        [ True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 8\n",
    "\n",
    "ones = torch.ones(seq_len, seq_len)\n",
    "causal_mask = torch.tril(ones).bool()\n",
    "\n",
    "padding_mask = torch.tensor([1, 1, 1, 1, 0, 0, 0, 0]).bool()\n",
    "padding_mask = padding_mask.unsqueeze(0).repeat(seq_len, 1)\n",
    "\n",
    "causal_mask = causal_mask.masked_fill_(~padding_mask, 0)\n",
    "causal_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "084ffb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention mask : \n",
      "tensor([[ True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False]])\n",
      "tensor([[[[ True, False, False, False, False],\n",
      "          [ True,  True, False, False, False],\n",
      "          [ True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False],\n",
      "          [ True,  True,  True,  True,  True]]]])\n",
      "Attention mask\n",
      "tensor([[[[ True, False, False, False, False],\n",
      "          [ True,  True, False, False, False],\n",
      "          [ True,  True,  True, False, False],\n",
      "          [ True,  True,  True, False, False],\n",
      "          [ True,  True,  True, False, False]]],\n",
      "\n",
      "\n",
      "        [[[ True, False, False, False, False],\n",
      "          [ True,  True, False, False, False],\n",
      "          [ True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False],\n",
      "          [ True,  True,  True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False, False, False, False],\n",
      "          [ True,  True, False, False, False],\n",
      "          [ True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False],\n",
      "          [ True,  True,  True,  True, False]]]])\n"
     ]
    }
   ],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, causal= True, attn_p = 0.0, proj_p = 0.0, bias = True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.causal = causal\n",
    "\n",
    "        self.query = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "\n",
    "    def forward(self, x, attention_mask = None):\n",
    "        batch_size, sequence_length, embed_dim = x.shape\n",
    "\n",
    "\n",
    "        q = self.query(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.key(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.value(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        attn = q @ k.transpose(-2, -1) * self.head_dim ** 0.5\n",
    "\n",
    "        if attention_mask is not None:\n",
    "                attention_mask = attention_mask.unsqueeze(1).unsqueeze(1) # .repeat(1, 1, sequence_length, 1) Optional\n",
    "        \n",
    "        if self.causal:\n",
    "\n",
    "            ones = torch.ones((sequence_length, sequence_length), device=attn.device)\n",
    "            causal_mask = torch.tril(ones).bool()\n",
    "            causal_mask = causal_mask.unsqueeze(0).unsqueeze(0)\n",
    "            print(causal_mask)\n",
    "\n",
    "            if attention_mask is not None:\n",
    "\n",
    "                causal_mask = causal_mask.repeat(batch_size, 1, 1, 1)\n",
    "                causal_mask = causal_mask.masked_fill_(~attention_mask, False)\n",
    "            \n",
    "\n",
    "            attn = attn.masked_fill_(~causal_mask, float(\"-inf\"))\n",
    "\n",
    "        #############################################\n",
    "\n",
    "        attn = attn.softmax(axis=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = attn @ v\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(batch_size, sequence_length, embed_dim)\n",
    "\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "\n",
    "seq_lens = [3, 5, 4]\n",
    "embed_dim = 9\n",
    "num_heads = 3\n",
    "\n",
    "a = SelfAttention(embed_dim, num_heads)\n",
    "\n",
    "rand = torch.randn(len(seq_lens), max(seq_lens), embed_dim)\n",
    "\n",
    "masks = torch.nn.utils.rnn.pad_sequence([torch.ones(l) for l in seq_lens], batch_first=True, padding_value=0).bool()\n",
    "print(\"Attention mask : \")\n",
    "print(masks)\n",
    "\n",
    "output = a(rand, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597900f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
