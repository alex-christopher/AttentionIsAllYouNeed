{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca3d49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input is :  torch.Size([4, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "batch_size = 4\n",
    "sequence_length = 64\n",
    "embed_dim = 128\n",
    "\n",
    "x = torch.randn(batch_size, sequence_length, embed_dim)\n",
    "print(\"Shape of input is : \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a9095f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26b5276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447a1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = (x @ x.transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c19cd2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5227622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(383.9728)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d56de33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10.4182, -0.3275, -1.2412,  ..., -1.0767, -0.7180, -0.2053],\n",
       "         [-0.3275, 10.6836,  0.8792,  ..., -0.6690, -0.9858, -0.5184],\n",
       "         [-1.2412,  0.8792,  9.5799,  ...,  0.3521, -0.6487, -0.7115],\n",
       "         ...,\n",
       "         [-1.0767, -0.6690,  0.3521,  ...,  9.4699, -0.2579,  0.5086],\n",
       "         [-0.7180, -0.9858, -0.6487,  ..., -0.2579, 11.2757, -1.2471],\n",
       "         [-0.2053, -0.5184, -0.7115,  ...,  0.5086, -1.2471, 12.5451]],\n",
       "\n",
       "        [[12.4161,  0.9529,  0.4513,  ...,  0.0627, -0.3439,  1.1411],\n",
       "         [ 0.9529, 11.4158, -1.2582,  ...,  0.7327, -0.7804,  0.6689],\n",
       "         [ 0.4513, -1.2582, 10.3306,  ...,  0.2178, -2.4212,  0.8338],\n",
       "         ...,\n",
       "         [ 0.0627,  0.7327,  0.2178,  ..., 12.3123, -0.5745,  1.4630],\n",
       "         [-0.3439, -0.7804, -2.4212,  ..., -0.5745, 12.5936, -0.2378],\n",
       "         [ 1.1411,  0.6689,  0.8338,  ...,  1.4630, -0.2378, 10.8373]],\n",
       "\n",
       "        [[10.8862,  0.1236, -1.9391,  ..., -0.6725, -0.1161,  0.2866],\n",
       "         [ 0.1236, 13.6696,  0.5223,  ...,  0.7340,  0.1019,  0.8778],\n",
       "         [-1.9391,  0.5223, 11.5089,  ..., -1.9318,  1.5898, -0.4173],\n",
       "         ...,\n",
       "         [-0.6725,  0.7340, -1.9318,  ..., 11.4105, -1.2859, -0.5806],\n",
       "         [-0.1161,  0.1019,  1.5898,  ..., -1.2859, 10.8690, -0.4847],\n",
       "         [ 0.2866,  0.8778, -0.4173,  ..., -0.5806, -0.4847,  8.6562]],\n",
       "\n",
       "        [[12.9906,  1.7693,  0.2145,  ...,  1.1216, -0.3963, -0.0766],\n",
       "         [ 1.7693, 14.7321,  0.0856,  ..., -0.4701, -2.4663,  2.3497],\n",
       "         [ 0.2145,  0.0856,  9.5395,  ...,  0.2751, -0.9248, -0.1078],\n",
       "         ...,\n",
       "         [ 1.1216, -0.4701,  0.2751,  ..., 12.1852,  0.1842, -2.2258],\n",
       "         [-0.3963, -2.4663, -0.9248,  ...,  0.1842, 13.2833, -1.0505],\n",
       "         [-0.0766,  2.3497, -0.1078,  ..., -2.2258, -1.0505, 11.8090]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = (x @ x.transpose(1, 2)) / (embed_dim ** 0.5)\n",
    "\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b781a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.9681e-01, 2.1470e-05, 8.6094e-06,  ..., 1.0149e-05,\n",
       "          1.4528e-05, 2.4260e-05],\n",
       "         [1.6480e-05, 9.9764e-01, 5.5082e-05,  ..., 1.1712e-05,\n",
       "          8.5317e-06, 1.3616e-05],\n",
       "         [1.9831e-05, 1.6529e-04, 9.9285e-01,  ..., 9.7569e-05,\n",
       "          3.5865e-05, 3.3681e-05],\n",
       "         ...,\n",
       "         [2.6140e-05, 3.9298e-05, 1.0910e-04,  ..., 9.9455e-01,\n",
       "          5.9280e-05, 1.2759e-04],\n",
       "         [6.1759e-06, 4.7251e-06, 6.6192e-06,  ..., 9.7842e-06,\n",
       "          9.9890e-01, 3.6386e-06],\n",
       "         [2.9000e-06, 2.1204e-06, 1.7479e-06,  ..., 5.9215e-06,\n",
       "          1.0231e-06, 9.9958e-01]],\n",
       "\n",
       "        [[9.9964e-01, 1.0506e-05, 6.3626e-06,  ..., 4.3139e-06,\n",
       "          2.8726e-06, 1.2683e-05],\n",
       "         [2.8537e-05, 9.9865e-01, 3.1271e-06,  ..., 2.2898e-05,\n",
       "          5.0429e-06, 2.1482e-05],\n",
       "         [5.1061e-05, 9.2392e-06, 9.9678e-01,  ..., 4.0428e-05,\n",
       "          2.8879e-06, 7.4852e-05],\n",
       "         ...,\n",
       "         [4.7843e-06, 9.3494e-06, 5.5869e-06,  ..., 9.9939e-01,\n",
       "          2.5296e-06, 1.9407e-05],\n",
       "         [2.4055e-06, 1.5547e-06, 3.0133e-07,  ..., 1.9100e-06,\n",
       "          9.9974e-01, 2.6746e-06],\n",
       "         [6.1398e-05, 3.8287e-05, 4.5154e-05,  ..., 8.4716e-05,\n",
       "          1.5463e-05, 9.9808e-01]],\n",
       "\n",
       "        [[9.9886e-01, 2.1152e-05, 2.6886e-06,  ..., 9.5413e-06,\n",
       "          1.6643e-05, 2.4897e-05],\n",
       "         [1.3092e-06, 9.9989e-01, 1.9505e-06,  ..., 2.4104e-06,\n",
       "          1.2811e-06, 2.7832e-06],\n",
       "         [1.4425e-06, 1.6908e-05, 9.9892e-01,  ..., 1.4530e-06,\n",
       "          4.9171e-05, 6.6076e-06],\n",
       "         ...,\n",
       "         [5.6493e-06, 2.3059e-05, 1.6035e-06,  ..., 9.9898e-01,\n",
       "          3.0590e-06, 6.1934e-06],\n",
       "         [1.6918e-05, 2.1040e-05, 9.3160e-05,  ..., 5.2518e-06,\n",
       "          9.9804e-01, 1.1703e-05],\n",
       "         [2.2777e-04, 4.1137e-04, 1.1266e-04,  ..., 9.5691e-05,\n",
       "          1.0532e-04, 9.8256e-01]],\n",
       "\n",
       "        [[9.9980e-01, 1.3384e-05, 2.8270e-06,  ..., 7.0031e-06,\n",
       "          1.5349e-06, 2.1131e-06],\n",
       "         [2.3460e-06, 9.9996e-01, 4.3563e-07,  ..., 2.4991e-07,\n",
       "          3.3950e-08, 4.1915e-06],\n",
       "         [8.8572e-05, 7.7864e-05, 9.9330e-01,  ..., 9.4104e-05,\n",
       "          2.8346e-05, 6.4172e-05],\n",
       "         ...,\n",
       "         [1.5664e-05, 3.1889e-06, 6.7181e-06,  ..., 9.9947e-01,\n",
       "          6.1344e-06, 5.5098e-07],\n",
       "         [1.1455e-06, 1.4454e-07, 6.7519e-07,  ..., 2.0467e-06,\n",
       "          9.9982e-01, 5.9547e-07],\n",
       "         [6.8824e-06, 7.7881e-05, 6.6710e-06,  ..., 8.0230e-07,\n",
       "          2.5988e-06, 9.9905e-01]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mat = similarity.softmax(dim = 2)\n",
    "\n",
    "attn_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02a0a33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 64, 64]), torch.Size([4, 64, 128]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mat.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f75062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = (attn_mat @ x)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa972806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 20])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(10, 20)\n",
    "\n",
    "rand = torch.randn(4, 6, 10)\n",
    "\n",
    "linear(rand).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314fb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single head attention\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, embedding_dimension):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embedding_dimension\n",
    "\n",
    "        self.query = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.key = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.value = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        similarity = (q @ k.transpose(1, 2)) / self.embed_dim ** 0.5\n",
    "        attention = similarity.softmax(axis=2)\n",
    "        output = attention @ v\n",
    "\n",
    "rand = torch.randn(4, 64, 128)\n",
    "\n",
    "attn = Attention(embedding_dimension=128)\n",
    "attn(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b135953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dimension, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embedding_dimension\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "\n",
    "        self.multihead_qkv = nn.ModuleList()\n",
    "\n",
    "        for head in range(num_heads):\n",
    "            qkv_proj = nn.ModuleDict(\n",
    "                [\n",
    "                  [\"Q\", nn.Linear(self.embed_dim, self.head_dim)],\n",
    "                  [\"K\", nn.Linear(self.embed_dim, self.head_dim)],\n",
    "                  [\"V\", nn.Linear(self.embed_dim, self.head_dim)]  \n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.multihead_qkv.append(qkv_proj)\n",
    "\n",
    "        self.proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        head_outs = []\n",
    "\n",
    "        for head in self.multihead_qkv:\n",
    "\n",
    "            q = head[\"Q\"](x)\n",
    "            k = head[\"K\"](x)\n",
    "            v = head[\"V\"](x)\n",
    "\n",
    "            similarity = (q @ k.transpose(1, 2)) / self.head_dim ** 0.5\n",
    "            attention = similarity.softmax(axis=-1)\n",
    "            output = attention @ v\n",
    "\n",
    "            head_outs.append(output)\n",
    "\n",
    "        head_outs = torch.cat(head_outs, dim=-1)\n",
    "\n",
    "        out = self.proj(head_outs)\n",
    "\n",
    "        return out\n",
    "            \n",
    "\n",
    "rand = torch.randn(4, 64, 128)\n",
    "attn = MultiHeadAttention(128, 4)\n",
    "attn(rand).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d2f67e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inpur shape :  torch.Size([5, 10]) Output shape :  torch.Size([5, 30])\n",
      "Inpur shape :  torch.Size([5, 1, 2, 4, 10]) Output shape :  torch.Size([5, 1, 2, 4, 30])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(10, 30)\n",
    "\n",
    "tensor_1 = torch.randn(5, 10)\n",
    "tensor_1_out = fc(tensor_1)\n",
    "\n",
    "print(\"Inpur shape : \", tensor_1.shape, \"Output shape : \", tensor_1_out.shape)\n",
    "\n",
    "tensor_2 = torch.randn(5, 1, 2, 4, 10)\n",
    "tensor_2_out = fc(tensor_2)\n",
    "\n",
    "print(\"Inpur shape : \", tensor_2.shape, \"Output shape : \", tensor_2_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f9d07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(1, 8, 9)\n",
    "fc = nn.Linear(9, 9)\n",
    "\n",
    "q = fc(tensor)\n",
    "\n",
    "chunk1, chun2, chunk3 = torch.chunk(q, 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b947a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6284, 0.7227, 0.9596],\n",
       "          [0.4593, 0.6037, 0.8552],\n",
       "          [0.4661, 1.0673, 1.0934],\n",
       "          [0.8888, 0.7978, 0.9769],\n",
       "          [0.1879, 0.7750, 0.9653],\n",
       "          [0.6388, 0.9627, 1.3669]],\n",
       "\n",
       "         [[0.4987, 0.4611, 1.1365],\n",
       "          [0.7592, 0.4052, 1.3393],\n",
       "          [0.5425, 0.4535, 1.1568],\n",
       "          [0.8584, 0.8129, 2.0019],\n",
       "          [1.1036, 0.8007, 2.1859],\n",
       "          [0.7237, 0.8247, 1.8851]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1, 2, 6, 4)\n",
    "b = torch.rand(1, 2, 4, 3)\n",
    "\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "155ed6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 128])\n",
      "torch.Size([4, 16, 128])\n"
     ]
    }
   ],
   "source": [
    "class SelfAttentionEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, attn_p = 0.0, proj_p = 0.0, bias = True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.query = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length, embed_dim = x.shape\n",
    "\n",
    "        print(x.shape)\n",
    "\n",
    "        q = self.query(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.key(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.value(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        attn = q @ k.transpose(-2, -1) * self.head_dim ** 0.5\n",
    "        attn = attn.softmax(axis=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = attn @ v\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(batch_size, sequence_length, embed_dim)\n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "\n",
    "rand = torch.randn(4, 16, 128)\n",
    "attn = SelfAttentionEncoder(128, 4)\n",
    "attn(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e0f4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n",
      "torch.Size([1, 6, 6]) torch.Size([1, 6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 6, 6]), torch.Size([1, 6, 6]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_attn = torch.rand(1, 6, 6)\n",
    "\n",
    "attention_mask = torch.tensor([1, 1, 1, 1, 0, 0]).unsqueeze(0).bool()\n",
    "print(attention_mask.shape)\n",
    "attention_mask = attention_mask.unsqueeze(1).repeat(1, 6, 1)\n",
    "print(attention_mask.shape, rand_attn.shape)\n",
    "\n",
    "# torch.softmax(rand_attn.masked_fill(~attention_mask, -float(\"inf\")), axis=-1)\n",
    "\n",
    "attention_mask.shape, rand_attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbaa693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False]],\n",
      "\n",
      "         [[ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False],\n",
      "          [ True,  True,  True,  True, False, False]]]])\n"
     ]
    }
   ],
   "source": [
    "rand_attn = torch.rand(1, 2, 6, 6)\n",
    "\n",
    "attention_mask = torch.tensor([1, 1, 1, 1, 0, 0]).unsqueeze(0).bool()\n",
    "attention_mask = attention_mask.unsqueeze(1).unsqueeze(1)\n",
    "attention_mask = attention_mask.repeat(1, 2, 6, 1)\n",
    "print(attention_mask)\n",
    "\n",
    "# rand_attn.masked_fill_(~attention_mask, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3aa60987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention mask : \n",
      "tensor([[ True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False]])\n",
      "torch.Size([3, 5, 9])\n",
      "Attention mask\n",
      "tensor([[[ True,  True,  True, False, False]]])\n",
      "tensor([[[-2.5752,  1.2256,  0.3576, -0.7280,  1.3640],\n",
      "         [-1.0284,  1.5719,  0.2485, -0.1938,  0.9666],\n",
      "         [-2.8719,  2.1797,  0.0179, -2.5782,  0.8866],\n",
      "         [-0.2487,  0.0902,  0.2461,  0.7834,  0.5637],\n",
      "         [-0.6897,  0.8424,  0.1392, -0.1759,  0.5518]],\n",
      "\n",
      "        [[ 0.0471,  0.3792, -0.4356,  0.5821,  0.4571],\n",
      "         [ 0.3958, -0.7316,  0.4995, -0.0352, -0.1791],\n",
      "         [ 1.4831, -1.3442,  0.6859,  1.0190,  0.4052],\n",
      "         [-1.0623,  0.0193, -0.3651, -0.1329, -0.2070],\n",
      "         [ 0.0291,  0.0138,  0.2136, -0.4241, -0.2424]],\n",
      "\n",
      "        [[-0.3754,  0.0525,  0.8761,  0.5526, -0.2392],\n",
      "         [-1.5586,  2.0417,  0.4571, -2.6434,  1.8729],\n",
      "         [-0.9346,  1.1810, -0.4002, -1.8324,  1.6955],\n",
      "         [ 0.8070, -0.7053, -0.7454,  0.4670, -0.5065],\n",
      "         [ 0.7773, -0.6365, -1.0407,  0.2133, -0.2086]]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[[[-2.5752,  1.2256,  0.3576,    -inf,    -inf],\n",
      "          [-1.0284,  1.5719,  0.2485,    -inf,    -inf],\n",
      "          [-2.8719,  2.1797,  0.0179,    -inf,    -inf],\n",
      "          [-0.2487,  0.0902,  0.2461,    -inf,    -inf],\n",
      "          [-0.6897,  0.8424,  0.1392,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0471,  0.3792, -0.4356,    -inf,    -inf],\n",
      "          [ 0.3958, -0.7316,  0.4995,    -inf,    -inf],\n",
      "          [ 1.4831, -1.3442,  0.6859,    -inf,    -inf],\n",
      "          [-1.0623,  0.0193, -0.3651,    -inf,    -inf],\n",
      "          [ 0.0291,  0.0138,  0.2136,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3754,  0.0525,  0.8761,    -inf,    -inf],\n",
      "          [-1.5586,  2.0417,  0.4571,    -inf,    -inf],\n",
      "          [-0.9346,  1.1810, -0.4002,    -inf,    -inf],\n",
      "          [ 0.8070, -0.7053, -0.7454,    -inf,    -inf],\n",
      "          [ 0.7773, -0.6365, -1.0407,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7748,  0.4918,  0.5779, -0.7030,  2.1131],\n",
      "          [ 0.5323,  0.1593,  0.5113, -0.2757,  2.0908],\n",
      "          [-0.1286, -0.1213, -0.1094,  0.3279, -0.1763],\n",
      "          [ 0.1175,  0.2352, -0.1424,  0.2481, -0.1479],\n",
      "          [ 0.3834,  0.2179,  0.3463, -0.5052,  1.1003]],\n",
      "\n",
      "         [[-0.7315, -0.3701,  0.4094,  0.1684, -0.4103],\n",
      "          [-0.9879, -0.8104,  0.2751,  0.6927, -0.5576],\n",
      "          [ 0.3643, -0.0988, -0.1536, -0.2489,  0.3242],\n",
      "          [ 0.1974, -1.1629, -0.6560,  0.7132,  0.3333],\n",
      "          [-0.2555, -0.4907, -0.0437,  0.3352, -0.0920]],\n",
      "\n",
      "         [[ 0.4662,  0.2850,  1.3757, -0.0972,  0.5442],\n",
      "          [-0.0751,  0.0605,  0.9740, -0.8406,  0.2236],\n",
      "          [-1.0672, -2.1941,  0.0741,  0.1056, -0.6873],\n",
      "          [-1.0287, -0.8509, -0.7675, -0.9018, -0.6755],\n",
      "          [ 0.4670,  0.4339,  1.3393, -0.2515,  0.5584]]],\n",
      "\n",
      "\n",
      "        [[[-0.1993,  1.7294, -0.7861,  0.0480,    -inf],\n",
      "          [-0.6116, -4.0076,  1.4906, -0.1771,    -inf],\n",
      "          [ 2.6744,  5.2553, -1.1932,  0.7887,    -inf],\n",
      "          [ 2.0240,  2.7455, -0.1377,  1.1516,    -inf],\n",
      "          [-0.5935, -0.6873,  0.0240, -0.2545,    -inf]],\n",
      "\n",
      "         [[ 0.4151,  1.2058, -0.9729,  0.3695,    -inf],\n",
      "          [-0.4018, -1.1642,  0.5443, -1.0519,    -inf],\n",
      "          [ 0.1898,  0.5634, -1.4230, -1.5110,    -inf],\n",
      "          [-0.2981, -0.4633, -1.2946, -1.3832,    -inf],\n",
      "          [ 0.1636,  0.3595,  0.0134,  0.1511,    -inf]],\n",
      "\n",
      "         [[-1.0258, -0.1762, -0.3443,  0.2623,    -inf],\n",
      "          [ 1.3840, -2.1709,  0.7998,  0.0459,    -inf],\n",
      "          [ 1.0426, -1.4173, -0.7339, -0.5352,    -inf],\n",
      "          [ 0.2514, -1.1578,  0.2841,  0.1483,    -inf],\n",
      "          [-0.1532,  0.7879, -0.0929, -0.0666,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[[[0.0155, 0.6934, 0.2911, 0.0000, 0.0000],\n",
      "          [0.0554, 0.7460, 0.1986, 0.0000, 0.0000],\n",
      "          [0.0057, 0.8916, 0.1027, 0.0000, 0.0000],\n",
      "          [0.2473, 0.3471, 0.4056, 0.0000, 0.0000],\n",
      "          [0.1263, 0.5844, 0.2893, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3321, 0.4629, 0.2050, 0.0000, 0.0000],\n",
      "          [0.4110, 0.1331, 0.4559, 0.0000, 0.0000],\n",
      "          [0.6623, 0.0392, 0.2985, 0.0000, 0.0000],\n",
      "          [0.1679, 0.4951, 0.3371, 0.0000, 0.0000],\n",
      "          [0.3137, 0.3090, 0.3773, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.1659, 0.2544, 0.5797, 0.0000, 0.0000],\n",
      "          [0.0222, 0.8115, 0.1664, 0.0000, 0.0000],\n",
      "          [0.0909, 0.7540, 0.1551, 0.0000, 0.0000],\n",
      "          [0.6983, 0.1539, 0.1478, 0.0000, 0.0000],\n",
      "          [0.7115, 0.1730, 0.1155, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1512, 0.1139, 0.1241, 0.0345, 0.5763],\n",
      "          [0.1271, 0.0876, 0.1245, 0.0567, 0.6041],\n",
      "          [0.1799, 0.1812, 0.1834, 0.2840, 0.1715],\n",
      "          [0.2082, 0.2342, 0.1606, 0.2373, 0.1597],\n",
      "          [0.1897, 0.1608, 0.1828, 0.0780, 0.3886]],\n",
      "\n",
      "         [[0.1064, 0.1526, 0.3328, 0.2615, 0.1466],\n",
      "          [0.0791, 0.0945, 0.2798, 0.4249, 0.1217],\n",
      "          [0.2683, 0.1688, 0.1598, 0.1453, 0.2577],\n",
      "          [0.2221, 0.0570, 0.0946, 0.3720, 0.2544],\n",
      "          [0.1664, 0.1315, 0.2057, 0.3004, 0.1960]],\n",
      "\n",
      "         [[0.1676, 0.1398, 0.4161, 0.0954, 0.1812],\n",
      "          [0.1468, 0.1681, 0.4190, 0.0683, 0.1979],\n",
      "          [0.1093, 0.0354, 0.3422, 0.3532, 0.1598],\n",
      "          [0.1652, 0.1974, 0.2146, 0.1876, 0.2352],\n",
      "          [0.1683, 0.1628, 0.4026, 0.0820, 0.1844]]],\n",
      "\n",
      "\n",
      "        [[[0.1029, 0.7081, 0.0572, 0.1318, 0.0000],\n",
      "          [0.0929, 0.0031, 0.7605, 0.1435, 0.0000],\n",
      "          [0.0695, 0.9185, 0.0015, 0.0105, 0.0000],\n",
      "          [0.2785, 0.5730, 0.0321, 0.1164, 0.0000],\n",
      "          [0.1935, 0.1762, 0.3588, 0.2716, 0.0000]],\n",
      "\n",
      "         [[0.2268, 0.5000, 0.0566, 0.2166, 0.0000],\n",
      "          [0.2191, 0.1022, 0.5643, 0.1144, 0.0000],\n",
      "          [0.3527, 0.5125, 0.0703, 0.0644, 0.0000],\n",
      "          [0.3914, 0.3318, 0.1445, 0.1322, 0.0000],\n",
      "          [0.2460, 0.2993, 0.2117, 0.2430, 0.0000]],\n",
      "\n",
      "         [[0.1118, 0.2616, 0.2211, 0.4055, 0.0000],\n",
      "          [0.5410, 0.0155, 0.3016, 0.1419, 0.0000],\n",
      "          [0.6844, 0.0585, 0.1158, 0.1413, 0.0000],\n",
      "          [0.3145, 0.0768, 0.3249, 0.2837, 0.0000],\n",
      "          [0.1750, 0.4484, 0.1858, 0.1908, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 3, 5, 5])\n",
      "torch.Size([3, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, attn_p = 0.0, proj_p = 0.0, bias = True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.query = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "\n",
    "    def forward(self, x, attention_mask = None):\n",
    "        batch_size, sequence_length, embed_dim = x.shape\n",
    "\n",
    "        print(x.shape)\n",
    "\n",
    "        q = self.query(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.key(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.value(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        attn = q @ k.transpose(-2, -1) * self.head_dim ** 0.5\n",
    "        \n",
    "        #############################################\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            print(\"Attention mask\")\n",
    "\n",
    "            attention_mask = attention_mask.unsqueeze(1).unsqueeze(1) # .repeat(1, 1, sequence_length, 1) Optional\n",
    "            print(attention_mask[0])\n",
    "            print(attn[0])\n",
    "\n",
    "            attn = attn.masked_fill_(~attention_mask, float(\"-inf\"))\n",
    "            print(attn)\n",
    "\n",
    "        #############################################\n",
    "\n",
    "        attn = attn.softmax(axis=-1)\n",
    "        print(attn)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = attn @ v\n",
    "        print(attn.shape)\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(batch_size, sequence_length, embed_dim)\n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "\n",
    "seq_lens = [3, 5, 4]\n",
    "embed_dim = 9\n",
    "num_heads = 3\n",
    "\n",
    "a = SelfAttention(embed_dim, num_heads)\n",
    "\n",
    "rand = torch.randn(len(seq_lens), max(seq_lens), embed_dim)\n",
    "\n",
    "masks = torch.nn.utils.rnn.pad_sequence([torch.ones(l) for l in seq_lens], batch_first=True, padding_value=0).bool()\n",
    "print(\"Attention mask : \")\n",
    "print(masks)\n",
    "\n",
    "output = a(rand, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abb7462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False, False, False, False],\n",
       "        [ True,  True, False, False, False, False, False, False],\n",
       "        [ True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 8\n",
    "\n",
    "ones = torch.ones(seq_len, seq_len)\n",
    "causal_mask = torch.tril(ones).bool()\n",
    "\n",
    "padding_mask = torch.tensor([1, 1, 1, 1, 0, 0, 0, 0]).bool()\n",
    "padding_mask = padding_mask.unsqueeze(0).repeat(seq_len, 1)\n",
    "\n",
    "causal_mask = causal_mask.masked_fill_(~padding_mask, 0)\n",
    "causal_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "084ffb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention mask : \n",
      "tensor([[ True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True, False]])\n",
      "torch.Size([3, 5, 9])\n",
      "Attention mask\n",
      "tensor([[[ True,  True,  True, False, False]]])\n",
      "tensor([[[ 5.6995e-01,  3.3796e-01,  6.3030e-01,  8.9603e-01, -2.3478e-01],\n",
      "         [ 2.5791e-01,  2.6351e-01,  7.8042e-01,  6.7147e-01, -5.4165e-01],\n",
      "         [-7.5067e-01, -1.0092e-01,  9.2417e-01,  2.5597e-01, -1.1230e+00],\n",
      "         [ 2.6883e-01,  3.1667e-01,  1.1072e+00,  1.1027e+00, -7.6815e-01],\n",
      "         [ 3.4245e-01, -5.6203e-04, -2.8669e-01,  7.5262e-01,  5.7168e-01]],\n",
      "\n",
      "        [[ 7.3013e-01,  3.6927e-01, -2.1133e-01,  6.1256e-01, -2.9070e-01],\n",
      "         [ 5.5573e-01,  2.7058e-01, -2.7659e-02,  4.7476e-01, -1.1177e-01],\n",
      "         [-1.3794e+00, -1.5250e-01, -7.3867e-01, -1.8175e+00, -3.7134e-01],\n",
      "         [-3.2434e-01, -1.4839e-01,  7.7238e-02, -2.9166e-01,  1.1593e-01],\n",
      "         [-1.0262e+00, -9.5097e-01, -7.4966e-01, -2.6475e-01, -4.6870e-01]],\n",
      "\n",
      "        [[ 2.4285e-01, -2.8272e-02, -1.5528e-01, -1.5050e-01,  2.0190e-02],\n",
      "         [-7.4881e-01,  4.7272e-01,  4.0757e-01,  6.8395e-01, -1.5225e-01],\n",
      "         [-6.4027e-02, -2.5196e-01,  5.7930e-02, -9.2777e-02,  1.8387e-01],\n",
      "         [ 4.3376e-01,  1.3757e+00, -8.7756e-01,  7.1353e-01,  1.1044e+00],\n",
      "         [ 9.3135e-01,  1.5636e+00, -9.7842e-01,  4.1364e-01, -4.4910e-03]]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[[[ 5.6995e-01,  3.3796e-01,  6.3030e-01,        -inf,        -inf],\n",
      "          [ 2.5791e-01,  2.6351e-01,  7.8042e-01,        -inf,        -inf],\n",
      "          [-7.5067e-01, -1.0092e-01,  9.2417e-01,        -inf,        -inf],\n",
      "          [ 2.6883e-01,  3.1667e-01,  1.1072e+00,        -inf,        -inf],\n",
      "          [ 3.4245e-01, -5.6203e-04, -2.8669e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 7.3013e-01,  3.6927e-01, -2.1133e-01,        -inf,        -inf],\n",
      "          [ 5.5573e-01,  2.7058e-01, -2.7659e-02,        -inf,        -inf],\n",
      "          [-1.3794e+00, -1.5250e-01, -7.3867e-01,        -inf,        -inf],\n",
      "          [-3.2434e-01, -1.4839e-01,  7.7238e-02,        -inf,        -inf],\n",
      "          [-1.0262e+00, -9.5097e-01, -7.4966e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.4285e-01, -2.8272e-02, -1.5528e-01,        -inf,        -inf],\n",
      "          [-7.4881e-01,  4.7272e-01,  4.0757e-01,        -inf,        -inf],\n",
      "          [-6.4027e-02, -2.5196e-01,  5.7930e-02,        -inf,        -inf],\n",
      "          [ 4.3376e-01,  1.3757e+00, -8.7756e-01,        -inf,        -inf],\n",
      "          [ 9.3135e-01,  1.5636e+00, -9.7842e-01,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[-9.9740e-01,  9.1485e-01, -6.2721e-01,  2.3730e-01,  8.7231e-01],\n",
      "          [ 8.2650e-02, -3.6165e-01, -5.2250e-01, -5.7739e-01, -9.2078e-01],\n",
      "          [-4.0831e-01,  5.1064e-01, -1.2710e-01,  3.2817e-01,  8.0970e-01],\n",
      "          [ 5.4557e-01, -5.9566e-01, -7.1906e-02, -3.6937e-01, -6.8450e-01],\n",
      "          [ 8.0688e-01, -7.4912e-01,  2.1647e-01, -2.7514e-01, -6.4051e-01]],\n",
      "\n",
      "         [[ 2.3814e-01,  2.3956e+00,  9.9450e-01,  7.3764e-01,  5.8555e-01],\n",
      "          [-1.1781e+00, -6.6603e-01, -1.1010e+00, -9.9260e-03,  3.1211e-01],\n",
      "          [-4.1860e-01, -1.9106e+00, -1.0837e+00, -8.0808e-01, -9.2345e-02],\n",
      "          [ 1.1020e-01, -3.1326e-01, -1.6031e-01, -4.1144e-01,  1.7227e-01],\n",
      "          [ 1.2494e+00, -1.4480e+00,  2.2887e-01, -1.1271e+00, -4.8370e-01]],\n",
      "\n",
      "         [[ 1.8640e+00,  1.1161e+00,  8.5902e-01,  4.0196e-01,  4.8478e-01],\n",
      "          [ 4.1350e-01, -1.9970e-01, -1.3058e-01, -2.0132e-01, -2.4432e-02],\n",
      "          [-4.0975e-01, -7.1445e-01, -9.4701e-01, -2.8835e-01, -2.0273e-01],\n",
      "          [-1.3143e-01, -7.6277e-01, -1.0069e+00, -3.5954e-01, -1.9038e-01],\n",
      "          [ 8.5159e-01, -4.3804e-01, -9.2756e-01, -2.7319e-01,  5.8892e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3689e-01, -1.2734e+00,  3.0988e-01, -5.7993e-01,        -inf],\n",
      "          [ 3.1042e-01,  3.1038e-01,  1.2593e+00, -4.2818e-01,        -inf],\n",
      "          [ 2.1571e-01, -8.2736e-01,  4.2514e-01, -4.7393e-01,        -inf],\n",
      "          [-1.5216e-01,  1.4697e+00,  1.9200e-01,  1.1492e+00,        -inf],\n",
      "          [ 6.2259e-02, -3.4296e-02,  2.1047e-01, -1.0492e-01,        -inf]],\n",
      "\n",
      "         [[-1.4527e+00, -2.9680e-01, -5.4418e-01,  1.5178e+00,        -inf],\n",
      "          [ 4.0737e-01,  2.2124e-01,  2.0823e-01, -5.3539e-01,        -inf],\n",
      "          [-1.0417e-01,  1.4737e-01, -4.9662e-03, -1.2501e-01,        -inf],\n",
      "          [-8.2874e-01, -2.8996e-01, -4.1579e-01,  7.9518e-01,        -inf],\n",
      "          [-7.7037e-01, -2.6358e-01, -1.9086e-01,  1.3021e+00,        -inf]],\n",
      "\n",
      "         [[ 4.8636e-01, -1.3901e-01,  5.2745e-01, -3.3323e-01,        -inf],\n",
      "          [ 1.1092e+00, -1.9379e-01,  7.9941e-01, -7.1638e-01,        -inf],\n",
      "          [ 5.2466e-01, -4.4824e-01,  6.0312e-02, -5.0809e-01,        -inf],\n",
      "          [ 8.5698e-01, -6.1465e-03,  4.9905e-01, -4.9245e-01,        -inf],\n",
      "          [ 3.4741e-01, -9.9948e-02,  3.4154e-01, -2.3934e-01,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[[[0.3502, 0.2777, 0.3720, 0.0000, 0.0000],\n",
      "          [0.2709, 0.2724, 0.4567, 0.0000, 0.0000],\n",
      "          [0.1212, 0.2320, 0.6468, 0.0000, 0.0000],\n",
      "          [0.2293, 0.2405, 0.5302, 0.0000, 0.0000],\n",
      "          [0.4459, 0.3164, 0.2377, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4791, 0.3340, 0.1869, 0.0000, 0.0000],\n",
      "          [0.4329, 0.3255, 0.2416, 0.0000, 0.0000],\n",
      "          [0.1585, 0.5406, 0.3008, 0.0000, 0.0000],\n",
      "          [0.2713, 0.3234, 0.4053, 0.0000, 0.0000],\n",
      "          [0.2944, 0.3174, 0.3882, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4108, 0.3133, 0.2759, 0.0000, 0.0000],\n",
      "          [0.1321, 0.4481, 0.4198, 0.0000, 0.0000],\n",
      "          [0.3380, 0.2801, 0.3819, 0.0000, 0.0000],\n",
      "          [0.2608, 0.6689, 0.0703, 0.0000, 0.0000],\n",
      "          [0.3300, 0.6211, 0.0489, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0522, 0.3536, 0.0757, 0.1796, 0.3389],\n",
      "          [0.3257, 0.2088, 0.1778, 0.1683, 0.1194],\n",
      "          [0.0971, 0.2434, 0.1286, 0.2028, 0.3282],\n",
      "          [0.3919, 0.1252, 0.2114, 0.1570, 0.1145],\n",
      "          [0.4275, 0.0902, 0.2369, 0.1449, 0.1005]],\n",
      "\n",
      "         [[0.0674, 0.5827, 0.1435, 0.1110, 0.0954],\n",
      "          [0.0877, 0.1463, 0.0947, 0.2820, 0.3892],\n",
      "          [0.2630, 0.0592, 0.1352, 0.1782, 0.3645],\n",
      "          [0.2454, 0.1607, 0.1872, 0.1456, 0.2611],\n",
      "          [0.5891, 0.0397, 0.2123, 0.0547, 0.1041]],\n",
      "\n",
      "         [[0.4305, 0.2038, 0.1576, 0.0998, 0.1084],\n",
      "          [0.3023, 0.1637, 0.1754, 0.1635, 0.1951],\n",
      "          [0.2136, 0.1575, 0.1248, 0.2412, 0.2628],\n",
      "          [0.2712, 0.1442, 0.1130, 0.2159, 0.2557],\n",
      "          [0.4549, 0.1253, 0.0768, 0.1477, 0.1953]]],\n",
      "\n",
      "\n",
      "        [[[0.3652, 0.0806, 0.3928, 0.1613, 0.0000],\n",
      "          [0.1976, 0.1976, 0.5104, 0.0944, 0.0000],\n",
      "          [0.3239, 0.1141, 0.3994, 0.1625, 0.0000],\n",
      "          [0.0897, 0.4541, 0.1266, 0.3296, 0.0000],\n",
      "          [0.2555, 0.2320, 0.2963, 0.2162, 0.0000]],\n",
      "\n",
      "         [[0.0382, 0.1214, 0.0948, 0.7455, 0.0000],\n",
      "          [0.3290, 0.2732, 0.2696, 0.1282, 0.0000],\n",
      "          [0.2289, 0.2943, 0.2527, 0.2241, 0.0000],\n",
      "          [0.1075, 0.1843, 0.1625, 0.5456, 0.0000],\n",
      "          [0.0807, 0.1340, 0.1441, 0.6412, 0.0000]],\n",
      "\n",
      "         [[0.3314, 0.1773, 0.3453, 0.1460, 0.0000],\n",
      "          [0.4616, 0.1254, 0.3386, 0.0744, 0.0000],\n",
      "          [0.4233, 0.1600, 0.2660, 0.1507, 0.0000],\n",
      "          [0.4201, 0.1772, 0.2937, 0.1090, 0.0000],\n",
      "          [0.3135, 0.2004, 0.3117, 0.1744, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 3, 5, 5])\n",
      "torch.Size([3, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, causal= True, attn_p = 0.0, proj_p = 0.0, bias = True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.causal = causal\n",
    "\n",
    "        self.query = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "        self.attn_drop = nn.Dropout(attn_p)\n",
    "\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "\n",
    "    def forward(self, x, attention_mask = None):\n",
    "        batch_size, sequence_length, embed_dim = x.shape\n",
    "\n",
    "\n",
    "        q = self.query(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = self.key(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = self.value(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        attn = q @ k.transpose(-2, -1) * self.head_dim ** 0.5\n",
    "\n",
    "        if attention_mask is not None:\n",
    "                attention_mask = attention_mask.unsqueeze(1).unsqueeze(1) # .repeat(1, 1, sequence_length, 1) Optional\n",
    "        \n",
    "        if self.causal:\n",
    "\n",
    "            ones = torch.ones((sequence_length, sequence_length), device=attn.device)\n",
    "            causal_mask = torch.tril(ones).bool()\n",
    "            causal_mask = causal_mask.unsqueeze(0).unsqueeze(0)\n",
    "            print(causal_mask)\n",
    "\n",
    "            if attention_mask is not None:\n",
    "\n",
    "                causal_mask = causal_mask.repeat(batch_size, 1, 1, 1)\n",
    "                causal_mask = causal_mask.masked_fill_(~attention_mask, False)\n",
    "            \n",
    "\n",
    "            attn = attn.masked_fill_(~causal_mask, float(\"-inf\"))\n",
    "\n",
    "        #############################################\n",
    "\n",
    "        attn = attn.softmax(axis=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        x = attn @ v\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(batch_size, sequence_length, embed_dim)\n",
    "\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "\n",
    "seq_lens = [3, 5, 4]\n",
    "embed_dim = 9\n",
    "num_heads = 3\n",
    "\n",
    "a = SelfAttention(embed_dim, num_heads)\n",
    "\n",
    "rand = torch.randn(len(seq_lens), max(seq_lens), embed_dim)\n",
    "\n",
    "masks = torch.nn.utils.rnn.pad_sequence([torch.ones(l) for l in seq_lens], batch_first=True, padding_value=0).bool()\n",
    "print(\"Attention mask : \")\n",
    "print(masks)\n",
    "\n",
    "output = a(rand, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597900f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
