{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ca3d49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input is :  torch.Size([4, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "batch_size = 4\n",
    "sequence_length = 64\n",
    "embed_dim = 128\n",
    "\n",
    "x = torch.randn(batch_size, sequence_length, embed_dim)\n",
    "print(\"Shape of input is : \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8a9095f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d26b5276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "447a1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = (x @ x.transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c19cd2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 64])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5227622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(379.6125)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d56de33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2232e+01, -1.6930e-01, -3.2264e-01,  ..., -5.7459e-01,\n",
       "           1.8301e+00,  1.3866e+00],\n",
       "         [-1.6930e-01,  1.1490e+01, -8.9926e-01,  ...,  9.0709e-01,\n",
       "          -4.6978e-01,  1.2035e+00],\n",
       "         [-3.2264e-01, -8.9926e-01,  1.1293e+01,  ...,  2.7990e-01,\n",
       "          -1.3360e+00, -2.1876e+00],\n",
       "         ...,\n",
       "         [-5.7459e-01,  9.0709e-01,  2.7990e-01,  ...,  1.3370e+01,\n",
       "           1.9783e+00, -3.9287e-01],\n",
       "         [ 1.8301e+00, -4.6978e-01, -1.3360e+00,  ...,  1.9783e+00,\n",
       "           1.1668e+01,  7.7543e-01],\n",
       "         [ 1.3866e+00,  1.2035e+00, -2.1876e+00,  ..., -3.9287e-01,\n",
       "           7.7543e-01,  1.2696e+01]],\n",
       "\n",
       "        [[ 1.2441e+01,  6.4279e-01, -8.4803e-01,  ...,  2.0921e+00,\n",
       "          -1.3674e+00, -1.8692e-02],\n",
       "         [ 6.4279e-01,  1.3137e+01, -7.0683e-01,  ...,  6.0690e-01,\n",
       "           6.4403e-01, -1.6587e+00],\n",
       "         [-8.4803e-01, -7.0683e-01,  1.3899e+01,  ..., -5.2183e-01,\n",
       "           5.7990e-01,  4.4243e-01],\n",
       "         ...,\n",
       "         [ 2.0921e+00,  6.0690e-01, -5.2183e-01,  ...,  1.2770e+01,\n",
       "          -1.3555e-01,  1.5087e+00],\n",
       "         [-1.3674e+00,  6.4403e-01,  5.7990e-01,  ..., -1.3555e-01,\n",
       "           1.0343e+01, -5.9491e-01],\n",
       "         [-1.8692e-02, -1.6587e+00,  4.4243e-01,  ...,  1.5087e+00,\n",
       "          -5.9491e-01,  1.2091e+01]],\n",
       "\n",
       "        [[ 1.1271e+01,  2.2549e-01, -9.7048e-01,  ..., -1.4187e+00,\n",
       "          -3.3046e-01,  9.5815e-01],\n",
       "         [ 2.2549e-01,  7.3595e+00,  7.9385e-01,  ..., -6.4602e-01,\n",
       "           2.4079e-01,  9.7453e-02],\n",
       "         [-9.7048e-01,  7.9385e-01,  1.0201e+01,  ..., -2.5390e-01,\n",
       "          -7.6166e-01, -1.0899e+00],\n",
       "         ...,\n",
       "         [-1.4187e+00, -6.4602e-01, -2.5390e-01,  ...,  1.0304e+01,\n",
       "          -5.8958e-01,  1.8713e+00],\n",
       "         [-3.3046e-01,  2.4079e-01, -7.6166e-01,  ..., -5.8958e-01,\n",
       "           1.2504e+01,  1.7632e+00],\n",
       "         [ 9.5815e-01,  9.7453e-02, -1.0899e+00,  ...,  1.8713e+00,\n",
       "           1.7632e+00,  1.0950e+01]],\n",
       "\n",
       "        [[ 1.2477e+01,  4.1407e-01,  2.1834e+00,  ...,  3.0182e-01,\n",
       "           5.7731e-01, -4.5054e-01],\n",
       "         [ 4.1407e-01,  1.0147e+01,  9.4303e-01,  ..., -1.8066e-01,\n",
       "           1.0182e+00, -4.5665e-02],\n",
       "         [ 2.1834e+00,  9.4303e-01,  1.0020e+01,  ..., -1.2245e+00,\n",
       "          -5.5696e-01, -6.5633e-01],\n",
       "         ...,\n",
       "         [ 3.0182e-01, -1.8066e-01, -1.2245e+00,  ...,  1.1387e+01,\n",
       "           5.1678e-01, -1.2923e-02],\n",
       "         [ 5.7731e-01,  1.0182e+00, -5.5696e-01,  ...,  5.1678e-01,\n",
       "           1.2343e+01,  5.1076e-01],\n",
       "         [-4.5054e-01, -4.5665e-02, -6.5633e-01,  ..., -1.2923e-02,\n",
       "           5.1076e-01,  1.2398e+01]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = (x @ x.transpose(1, 2)) / (embed_dim ** 0.5)\n",
    "\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b781a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.9924e-01, 4.1118e-06, 3.5273e-06,  ..., 2.7417e-06,\n",
       "          3.0363e-05, 1.9487e-05],\n",
       "         [8.6280e-06, 9.9888e-01, 4.1581e-06,  ..., 2.5315e-05,\n",
       "          6.3887e-06, 3.4050e-05],\n",
       "         [9.0126e-06, 5.0632e-06, 9.9903e-01,  ..., 1.6464e-05,\n",
       "          3.2714e-06, 1.3961e-06],\n",
       "         ...,\n",
       "         [8.7881e-07, 3.8671e-06, 2.0654e-06,  ..., 9.9981e-01,\n",
       "          1.1287e-05, 1.0539e-06],\n",
       "         [5.3332e-05, 5.3478e-06, 2.2489e-06,  ..., 6.1852e-05,\n",
       "          9.9915e-01, 1.8577e-05],\n",
       "         [1.2247e-05, 1.0198e-05, 3.4341e-07,  ..., 2.0665e-06,\n",
       "          6.6469e-06, 9.9964e-01]],\n",
       "\n",
       "        [[9.9952e-01, 7.5147e-06, 1.6922e-06,  ..., 3.2014e-05,\n",
       "          1.0066e-06, 3.8782e-06],\n",
       "         [3.7468e-06, 9.9986e-01, 9.7168e-07,  ..., 3.6147e-06,\n",
       "          3.7514e-06, 3.7509e-07],\n",
       "         [3.9375e-07, 4.5346e-07, 9.9989e-01,  ..., 5.4562e-07,\n",
       "          1.6420e-06, 1.4311e-06],\n",
       "         ...,\n",
       "         [2.3052e-05, 5.2203e-06, 1.6885e-06,  ..., 9.9964e-01,\n",
       "          2.4846e-06, 1.2864e-05],\n",
       "         [8.1798e-06, 6.1139e-05, 5.7341e-05,  ..., 2.8038e-05,\n",
       "          9.9663e-01, 1.7711e-05],\n",
       "         [5.5027e-06, 1.0674e-06, 8.7265e-06,  ..., 2.5348e-05,\n",
       "          3.0926e-06, 9.9912e-01]],\n",
       "\n",
       "        [[9.9881e-01, 1.5936e-05, 4.8193e-06,  ..., 3.0785e-06,\n",
       "          9.1399e-06, 3.3157e-05],\n",
       "         [7.5456e-04, 9.4612e-01, 1.3321e-03,  ..., 3.1565e-04,\n",
       "          7.6619e-04, 6.6388e-04],\n",
       "         [1.4033e-05, 8.1919e-05, 9.9751e-01,  ..., 2.8731e-05,\n",
       "          1.7292e-05, 1.2453e-05],\n",
       "         ...,\n",
       "         [8.0803e-06, 1.7498e-05, 2.5899e-05,  ..., 9.9655e-01,\n",
       "          1.8514e-05, 2.1689e-04],\n",
       "         [2.6654e-06, 4.7190e-06, 1.7318e-06,  ..., 2.0570e-06,\n",
       "          9.9961e-01, 2.1628e-05],\n",
       "         [4.5662e-05, 1.9309e-05, 5.8896e-06,  ..., 1.1380e-04,\n",
       "          1.0214e-04, 9.9807e-01]],\n",
       "\n",
       "        [[9.9948e-01, 5.7676e-06, 3.3837e-05,  ..., 5.1552e-06,\n",
       "          6.7902e-06, 2.4294e-06],\n",
       "         [5.9053e-05, 9.9597e-01, 1.0022e-04,  ..., 3.2580e-05,\n",
       "          1.0805e-04, 3.7289e-05],\n",
       "         [3.9322e-04, 1.1375e-04, 9.9514e-01,  ..., 1.3020e-05,\n",
       "          2.5381e-05, 2.2981e-05],\n",
       "         ...,\n",
       "         [1.5314e-05, 9.4525e-06, 3.3282e-06,  ..., 9.9869e-01,\n",
       "          1.8986e-05, 1.1179e-05],\n",
       "         [7.7653e-06, 1.2068e-05, 2.4977e-06,  ..., 7.3092e-06,\n",
       "          9.9944e-01, 7.2653e-06],\n",
       "         [2.6280e-06, 3.9396e-06, 2.1392e-06,  ..., 4.0708e-06,\n",
       "          6.8724e-06, 9.9948e-01]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mat = similarity.softmax(dim = 2)\n",
    "\n",
    "attn_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02a0a33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 64, 64]), torch.Size([4, 64, 128]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mat.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2f75062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = (attn_mat @ x)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa972806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 20])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(10, 20)\n",
    "\n",
    "rand = torch.randn(4, 6, 10)\n",
    "\n",
    "linear(rand).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "314fb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single head attention\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, embedding_dimension):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embedding_dimension\n",
    "\n",
    "        self.query = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.key = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.value = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        similarity = (q @ k.transpose(1, 2)) / self.embed_dim ** 0.5\n",
    "        attention = similarity.softmax(axis=2)\n",
    "        output = attention @ v\n",
    "\n",
    "rand = torch.randn(4, 64, 128)\n",
    "\n",
    "attn = Attention(embedding_dimension=128)\n",
    "attn(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b135953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dimension, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embedding_dimension\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "\n",
    "        self.multihead_qkv = nn.ModuleList()\n",
    "\n",
    "        for head in range(num_heads):\n",
    "            qkv_proj = nn.ModuleDict(\n",
    "                [\n",
    "                  [\"Q\", nn.Linear(self.embed_dim, self.head_dim)],\n",
    "                  [\"K\", nn.Linear(self.embed_dim, self.head_dim)],\n",
    "                  [\"V\", nn.Linear(self.embed_dim, self.head_dim)]  \n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.multihead_qkv.append(qkv_proj)\n",
    "\n",
    "        self.proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        head_outs = []\n",
    "\n",
    "        for head in self.multihead_qkv:\n",
    "\n",
    "            q = head[\"Q\"](x)\n",
    "            k = head[\"K\"](x)\n",
    "            v = head[\"V\"](x)\n",
    "\n",
    "            similarity = (q @ k.transpose(1, 2)) / self.embed_dim ** 0.5\n",
    "            attention = similarity.softmax(axis=-1)\n",
    "            output = attention @ v\n",
    "\n",
    "            head_outs.append(output)\n",
    "\n",
    "        head_outs = torch.cat(head_outs, dim=-1)\n",
    "\n",
    "        out = self.proj(head_outs)\n",
    "\n",
    "        return out\n",
    "            \n",
    "\n",
    "rand = torch.randn(4, 64, 128)\n",
    "attn = MultiHeadAttention(128, 4)\n",
    "attn(rand).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d2f67e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inpur shape :  torch.Size([5, 10]) Output shape :  torch.Size([5, 30])\n",
      "Inpur shape :  torch.Size([5, 1, 2, 4, 10]) Output shape :  torch.Size([5, 1, 2, 4, 30])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(10, 30)\n",
    "\n",
    "tensor_1 = torch.randn(5, 10)\n",
    "tensor_1_out = fc(tensor_1)\n",
    "\n",
    "print(\"Inpur shape : \", tensor_1.shape, \"Output shape : \", tensor_1_out.shape)\n",
    "\n",
    "tensor_2 = torch.randn(5, 1, 2, 4, 10)\n",
    "tensor_2_out = fc(tensor_2)\n",
    "\n",
    "print(\"Inpur shape : \", tensor_2.shape, \"Output shape : \", tensor_2_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d07aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
