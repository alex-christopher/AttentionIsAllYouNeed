{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca3d49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input is :  torch.Size([4, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "batch_size = 4\n",
    "sequence_length = 64\n",
    "embed_dim = 128\n",
    "\n",
    "x = torch.randn(batch_size, sequence_length, embed_dim)\n",
    "print(\"Shape of input is : \", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8a9095f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d26b5276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "447a1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = (x @ x.transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c19cd2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5227622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(382.4670)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d56de33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0671e+01,  1.6319e+00,  1.5174e+00,  ...,  1.6468e-01,\n",
       "           1.1859e+00, -3.4202e-01],\n",
       "         [ 1.6319e+00,  1.3229e+01,  1.1566e+00,  ...,  1.9852e+00,\n",
       "          -1.3121e+00,  1.0552e+00],\n",
       "         [ 1.5174e+00,  1.1566e+00,  1.2758e+01,  ..., -1.2592e+00,\n",
       "           4.8482e-01, -7.6433e-01],\n",
       "         ...,\n",
       "         [ 1.6468e-01,  1.9852e+00, -1.2592e+00,  ...,  1.0402e+01,\n",
       "           8.9405e-01,  8.5003e-01],\n",
       "         [ 1.1859e+00, -1.3121e+00,  4.8482e-01,  ...,  8.9405e-01,\n",
       "           1.0861e+01, -4.6091e-01],\n",
       "         [-3.4202e-01,  1.0552e+00, -7.6433e-01,  ...,  8.5003e-01,\n",
       "          -4.6091e-01,  1.2508e+01]],\n",
       "\n",
       "        [[ 1.3754e+01,  1.0715e+00,  6.5350e-01,  ...,  7.7999e-02,\n",
       "           3.0643e-01,  1.6925e+00],\n",
       "         [ 1.0715e+00,  1.1790e+01, -1.2433e+00,  ..., -9.6008e-01,\n",
       "           5.8391e-01, -4.2873e-01],\n",
       "         [ 6.5350e-01, -1.2433e+00,  9.5225e+00,  ...,  5.8457e-01,\n",
       "           9.7283e-01,  1.1810e+00],\n",
       "         ...,\n",
       "         [ 7.7999e-02, -9.6008e-01,  5.8457e-01,  ...,  1.0780e+01,\n",
       "           1.9517e+00,  4.2548e-01],\n",
       "         [ 3.0643e-01,  5.8391e-01,  9.7283e-01,  ...,  1.9517e+00,\n",
       "           9.9224e+00,  5.8845e-01],\n",
       "         [ 1.6925e+00, -4.2873e-01,  1.1810e+00,  ...,  4.2548e-01,\n",
       "           5.8845e-01,  9.3922e+00]],\n",
       "\n",
       "        [[ 1.1594e+01,  6.3861e-01, -1.5790e+00,  ..., -7.4909e-01,\n",
       "           2.6996e-01, -2.6095e-01],\n",
       "         [ 6.3861e-01,  1.1723e+01, -1.2410e+00,  ...,  2.5559e+00,\n",
       "           8.9901e-01, -1.4702e+00],\n",
       "         [-1.5790e+00, -1.2410e+00,  1.2461e+01,  ...,  4.5055e-01,\n",
       "           1.6801e+00, -1.5434e+00],\n",
       "         ...,\n",
       "         [-7.4909e-01,  2.5559e+00,  4.5055e-01,  ...,  1.2346e+01,\n",
       "           9.9337e-04, -3.6965e-01],\n",
       "         [ 2.6996e-01,  8.9901e-01,  1.6801e+00,  ...,  9.9337e-04,\n",
       "           8.9560e+00, -2.7953e-01],\n",
       "         [-2.6095e-01, -1.4702e+00, -1.5434e+00,  ..., -3.6965e-01,\n",
       "          -2.7953e-01,  1.2859e+01]],\n",
       "\n",
       "        [[ 1.0988e+01,  5.4123e-02, -1.0908e+00,  ..., -3.4899e-01,\n",
       "           5.5971e-01, -7.8389e-01],\n",
       "         [ 5.4123e-02,  1.3347e+01,  7.0939e-01,  ...,  2.6777e+00,\n",
       "          -9.3601e-01,  1.5476e+00],\n",
       "         [-1.0908e+00,  7.0939e-01,  1.0401e+01,  ...,  9.5323e-01,\n",
       "           1.0667e-01,  7.0139e-01],\n",
       "         ...,\n",
       "         [-3.4899e-01,  2.6777e+00,  9.5323e-01,  ...,  1.0710e+01,\n",
       "          -2.9781e-01, -3.3522e-02],\n",
       "         [ 5.5971e-01, -9.3601e-01,  1.0667e-01,  ..., -2.9781e-01,\n",
       "           1.2870e+01,  9.7764e-01],\n",
       "         [-7.8389e-01,  1.5476e+00,  7.0139e-01,  ..., -3.3522e-02,\n",
       "           9.7764e-01,  1.3460e+01]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = (x @ x.transpose(1, 2)) / (embed_dim ** 0.5)\n",
    "\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b781a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.9766e-01, 1.1842e-04, 1.0561e-04,  ..., 2.7303e-05,\n",
       "          7.5811e-05, 1.6450e-05],\n",
       "         [9.1873e-06, 9.9981e-01, 5.7118e-06,  ..., 1.3081e-05,\n",
       "          4.8376e-07, 5.1610e-06],\n",
       "         [1.3123e-05, 9.1477e-06, 9.9975e-01,  ..., 8.1687e-07,\n",
       "          4.6727e-06, 1.3399e-06],\n",
       "         ...,\n",
       "         [3.5677e-05, 2.2032e-04, 8.5903e-06,  ..., 9.9626e-01,\n",
       "          7.3985e-05, 7.0799e-05],\n",
       "         [6.2693e-05, 5.1563e-06, 3.1098e-05,  ..., 4.6823e-05,\n",
       "          9.9780e-01, 1.2078e-05],\n",
       "         [2.6245e-06, 1.0613e-05, 1.7205e-06,  ..., 8.6448e-06,\n",
       "          2.3303e-06, 9.9964e-01]],\n",
       "\n",
       "        [[9.9987e-01, 3.1056e-06, 2.0446e-06,  ..., 1.1500e-06,\n",
       "          1.4451e-06, 5.7788e-06],\n",
       "         [2.2120e-05, 9.9920e-01, 2.1852e-06,  ..., 2.9006e-06,\n",
       "          1.3584e-05, 4.9346e-06],\n",
       "         [1.3972e-04, 2.0965e-05, 9.9319e-01,  ..., 1.3041e-04,\n",
       "          1.9228e-04, 2.3678e-04],\n",
       "         ...,\n",
       "         [2.2457e-05, 7.9527e-06, 3.7269e-05,  ..., 9.9826e-01,\n",
       "          1.4624e-04, 3.1787e-05],\n",
       "         [6.6327e-05, 8.7539e-05, 1.2915e-04,  ..., 3.4372e-04,\n",
       "          9.9504e-01, 8.7937e-05],\n",
       "         [4.4873e-04, 5.3797e-05, 2.6906e-04,  ..., 1.2640e-04,\n",
       "          1.4877e-04, 9.9063e-01]],\n",
       "\n",
       "        [[9.9920e-01, 1.7455e-05, 1.9002e-06,  ..., 4.3576e-06,\n",
       "          1.2073e-05, 7.0997e-06],\n",
       "         [1.5333e-05, 9.9897e-01, 2.3406e-06,  ..., 1.0430e-04,\n",
       "          1.9893e-05, 1.8611e-06],\n",
       "         [7.9838e-07, 1.1195e-06, 9.9966e-01,  ..., 6.0765e-06,\n",
       "          2.0780e-05, 8.2732e-07],\n",
       "         ...,\n",
       "         [2.0552e-06, 5.6001e-05, 6.8209e-06,  ..., 9.9951e-01,\n",
       "          4.3512e-06, 3.0035e-06],\n",
       "         [1.6698e-04, 3.1323e-04, 6.8406e-04,  ..., 1.2760e-04,\n",
       "          9.8847e-01, 9.6390e-05],\n",
       "         [2.0045e-06, 5.9817e-07, 5.5593e-07,  ..., 1.7980e-06,\n",
       "          1.9676e-06, 9.9972e-01]],\n",
       "\n",
       "        [[9.9854e-01, 1.7813e-05, 5.6690e-06,  ..., 1.1903e-05,\n",
       "          2.9533e-05, 7.7054e-06],\n",
       "         [1.6856e-06, 9.9978e-01, 3.2458e-06,  ..., 2.3235e-05,\n",
       "          6.2623e-07, 7.5052e-06],\n",
       "         [1.0192e-05, 6.1672e-05, 9.9759e-01,  ..., 7.8701e-05,\n",
       "          3.3754e-05, 6.1180e-05],\n",
       "         ...,\n",
       "         [1.5708e-05, 3.2403e-04, 5.7764e-05,  ..., 9.9718e-01,\n",
       "          1.6533e-05, 2.1534e-05],\n",
       "         [4.5040e-06, 1.0093e-06, 2.8632e-06,  ..., 1.9107e-06,\n",
       "          9.9979e-01, 6.8408e-06],\n",
       "         [6.5176e-07, 6.7089e-06, 2.8783e-06,  ..., 1.3803e-06,\n",
       "          3.7941e-06, 9.9983e-01]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mat = similarity.softmax(dim = 2)\n",
    "\n",
    "attn_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02a0a33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 64, 64]), torch.Size([4, 64, 128]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mat.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2f75062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = (attn_mat @ x)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa972806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 20])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(10, 20)\n",
    "\n",
    "rand = torch.randn(4, 6, 10)\n",
    "\n",
    "linear(rand).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "314fb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single head attention\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, embedding_dimension):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embedding_dimension\n",
    "\n",
    "        self.query = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.key = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "        self.value = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        similarity = (q @ k.transpose(1, 2)) / self.embed_dim ** 0.5\n",
    "        attention = similarity.softmax(axis=2)\n",
    "        output = attention @ v\n",
    "\n",
    "rand = torch.randn(4, 64, 128)\n",
    "\n",
    "attn = Attention(embedding_dimension=128)\n",
    "attn(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b135953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dimension, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embedding_dimension\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "\n",
    "        self.multihead_qkv = nn.ModuleList()\n",
    "\n",
    "        for head in range(num_heads):\n",
    "            qkv_proj = nn.ModuleDict(\n",
    "                [\n",
    "                  [\"Q\", nn.Linear(self.embed_dim, self.head_dim)],\n",
    "                  [\"K\", nn.Linear(self.embed_dim, self.head_dim)],\n",
    "                  [\"V\", nn.Linear(self.embed_dim, self.head_dim)]  \n",
    "                ]\n",
    "            )\n",
    "\n",
    "            self.multihead_qkv.append(qkv_proj)\n",
    "\n",
    "        self.proj = nn.Linear(self.embed_dim, self.embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        head_outs = []\n",
    "\n",
    "        for head in self.multihead_qkv:\n",
    "\n",
    "            q = head[\"Q\"](x)\n",
    "            k = head[\"K\"](x)\n",
    "            v = head[\"V\"](x)\n",
    "\n",
    "            similarity = (q @ k.transpose(1, 2)) / self.embed_dim ** 0.5\n",
    "            attention = similarity.softmax(axis=-1)\n",
    "            output = attention @ v\n",
    "\n",
    "            head_outs.append(output)\n",
    "\n",
    "        head_outs = torch.cat(head_outs, dim=-1)\n",
    "\n",
    "        out = self.proj(head_outs)\n",
    "\n",
    "        return out\n",
    "            \n",
    "\n",
    "rand = torch.randn(4, 64, 128)\n",
    "attn = MultiHeadAttention(128, 4)\n",
    "attn(rand).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d2f67e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inpur shape :  torch.Size([5, 10]) Output shape :  torch.Size([5, 30])\n",
      "Inpur shape :  torch.Size([5, 1, 2, 4, 10]) Output shape :  torch.Size([5, 1, 2, 4, 30])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(10, 30)\n",
    "\n",
    "tensor_1 = torch.randn(5, 10)\n",
    "tensor_1_out = fc(tensor_1)\n",
    "\n",
    "print(\"Inpur shape : \", tensor_1.shape, \"Output shape : \", tensor_1_out.shape)\n",
    "\n",
    "tensor_2 = torch.randn(5, 1, 2, 4, 10)\n",
    "tensor_2_out = fc(tensor_2)\n",
    "\n",
    "print(\"Inpur shape : \", tensor_2.shape, \"Output shape : \", tensor_2_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f9d07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(1, 8, 9)\n",
    "fc = nn.Linear(9, 9)\n",
    "\n",
    "q = fc(tensor)\n",
    "\n",
    "chunk1, chun2, chunk3 = torch.chunk(q, 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b947a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9982, 0.6132, 0.4496],\n",
       "          [0.5950, 0.3582, 0.3470],\n",
       "          [1.2939, 0.3835, 1.1406],\n",
       "          [0.9041, 0.3866, 0.6114],\n",
       "          [1.7082, 0.9127, 0.9175],\n",
       "          [0.8884, 0.6366, 0.5170]],\n",
       "\n",
       "         [[1.7517, 1.1400, 0.7104],\n",
       "          [2.2031, 1.3760, 0.8078],\n",
       "          [1.6440, 1.0661, 0.4796],\n",
       "          [0.7265, 0.5810, 0.3554],\n",
       "          [0.6167, 0.4061, 0.1374],\n",
       "          [1.5962, 1.1938, 0.7229]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1, 2, 6, 4)\n",
    "b = torch.rand(1, 2, 4, 3)\n",
    "\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "155ed6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 2, 64])\n"
     ]
    }
   ],
   "source": [
    "class SelfAttentionEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, attn_p = 0.0, proj_p = 0.0):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "        self.attn_drop = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.proj_drop = nn.Dropout(proj_p)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length, embed_dim = x.shape \n",
    "        q = self.query(x).reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
    "        print(q.shape)\n",
    "\n",
    "rand = torch.randn(4, 16, 128)\n",
    "attn = SelfAttentionEncoder(128, 2)\n",
    "attn(rand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0f4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
